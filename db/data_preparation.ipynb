{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c1c5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1930b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load credentials\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "ASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_API_ENDPOINT = os.getenv(\"ASTRA_DB_API_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3128c2",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "942dda00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total documents loaded: 1\n"
     ]
    }
   ],
   "source": [
    "# document loader\n",
    "import os\n",
    "from langchain_community.document_loaders import Docx2txtLoader \n",
    "\n",
    "file_path = \"d:/NextCountry/db/\"\n",
    "docx_files = [file for file in os.listdir(file_path) if file.endswith('.docx')]\n",
    "\n",
    "\n",
    "all_files = []  # To store pages from all files\n",
    "\n",
    "for docx in docx_files:\n",
    "    # print(f\"Processing {docx} file...\")  # Optional: Show progress\n",
    "    loader = Docx2txtLoader(file_path=os.path.join(file_path, docx))\n",
    "    \n",
    "    #  Load the documents for this file and append to `all_files`\n",
    "    for doc in loader.lazy_load():\n",
    "        all_files.append(doc)\n",
    "\n",
    "# Output all collected pages\n",
    "print(f\"✅ Total documents loaded: {len(all_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22392cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 300,\n",
    "        separators=[\n",
    "        \"\\n\"]\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(all_files)\n",
    "# splits\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b0f404",
   "metadata": {},
   "source": [
    "## Embedding Engine\n",
    "---\n",
    "HF credentials needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e996f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding model loaded\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "#NOTE: currently this is local model, need api inference\n",
    "hf_embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "print(\"embedding model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039b652",
   "metadata": {},
   "source": [
    "## Vector Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0f55bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected Database: next_country\n",
      "Collections found: ['uk_visa_details']\n"
     ]
    }
   ],
   "source": [
    "from astrapy import DataAPIClient\n",
    "\n",
    "# Initialize the client\n",
    "client = DataAPIClient(ASTRA_DB_APPLICATION_TOKEN)\n",
    "db = client.get_database_by_api_endpoint(\n",
    "  ASTRA_DB_API_ENDPOINT\n",
    ")\n",
    "\n",
    "print(f\"Connected Database: {db.info().name}\\nCollections found: {db.list_collection_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b8b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'uk_visa_details'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create collection\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=\"uk_visa_details\",      # this collection gets created automatically\n",
    "    embedding=hf_embedding_model,\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    namespace=\"default_keyspace\",\n",
    "    # autodetect_collection=True,   # set to True whille using it\n",
    ")\n",
    "\n",
    "vector_store.collection_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2d5d6",
   "metadata": {},
   "source": [
    "### Pushing data to collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e91389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:07<00:00,  7.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 added successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:08<00:00,  8.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 added successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:08<00:00,  8.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2 added successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:05<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3 added successfully\n"
     ]
    }
   ],
   "source": [
    "# push embedding to collection\n",
    "for i in range(0, len(splits), 10):\n",
    "    chunk = splits[i:i+10]\n",
    "    try:\n",
    "        # Add the chunk to the vector store\n",
    "        vector_store.add_documents(documents=chunk)\n",
    "        print(f\"Chunk {i//10} added successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding chunk {i//10}: {e}\")\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f125c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded to: uk_visa_details\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embeddings loaded to: {vector_store.collection_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b0970",
   "metadata": {},
   "source": [
    "## Check Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7685fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as data is already loaded\n",
    "\n",
    "vector_store = AstraDBVectorStore(\n",
    "    embedding = hf_embedding_model,\n",
    "    collection_name=\"uk_visa_details\",\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    autodetect_collection=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b93e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --->[Similarity score=14.789062]\n",
      "8. Evidence and Documentation\n",
      "\n",
      "A. Mandatory Documents\n",
      "\n",
      "Valid passport or travel document\n",
      "\n",
      "Proof of financial means (bank statements, payslips)\n",
      "\n",
      "Details of accommodation (hotel booking, invitation letter)\n",
      "\n",
      "Travel itinerary (if available)\n",
      "\n",
      "Evidence of employment or study in home country\n",
      "\n",
      "Previous travel history (visas, entry/exit stamps)\n",
      "\n",
      "Letter of invitation/sponsorship (if applicable)\n",
      "\n",
      "Parental consent for children\n",
      "\n",
      "B. Other Supporting Documents\n",
      "\n",
      "Proof of ties to home country (property deeds, family documents)\n",
      "\n",
      "Medical treatment evidence (if applicable)\n",
      "\n",
      "Conference/event invitations (for business visitors)\n",
      "\n",
      "9. Period and Conditions of Stay\n",
      "\n",
      "Standard grant: Up to 6 months per visit.\n",
      "\n",
      "Long-term multiple entry visas: Valid for 2, 5, or 10 years, but maximum 6 months per entry.\n",
      "\n",
      "No extensions except for certain medical or academic cases.\n",
      "\n",
      "Must leave the UK at or before visa expiry.\n",
      "\n",
      "10. Common Reasons for Refusal\n",
      "\n",
      "Doubts about genuine intention to visit or return.\n",
      "[{'source': 'd:/NextCountry/db/UNITED KINGDOM – VISA OPTIONS AND GUIDE.docx'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sanity check for similarity search\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    query=\"Documents for UK Visa\",\n",
    "    k=1,\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\" --->[Similarity score={score:3f}]\\n{res.page_content}\\n[{res.metadata}]\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
